{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTLof2N1ANwP"
      },
      "source": [
        "# Etapa 3 ‚Äî Automa√ß√£o Profissional do Processo\n",
        "\n",
        "Nesta etapa, o processo de extra√ß√£o, transforma√ß√£o e exporta√ß√£o de dados do e-commerce √© automatizado de forma modular e reprodut√≠vel, seguindo boas pr√°ticas de desenvolvimento em Python (PEP 8) e registro em log.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Iniciando automa√ß√£o de dados...\n",
            "\n",
            "‚úÖ Processo conclu√≠do com sucesso! Ticket m√©dio: R$ 391.43\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================\n",
        "# E-commerce Data Analytics - Automa√ß√£o de Processos\n",
        "# Autor: Gustavo de Paula Silva\n",
        "# Descri√ß√£o:\n",
        "#   Este script realiza a extra√ß√£o, transforma√ß√£o, an√°lise e\n",
        "#   exporta√ß√£o automatizada de dados de um e-commerce fict√≠cio,\n",
        "#   utilizando Python, SQLite e Pandas.\n",
        "# ==============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import os\n",
        "import logging\n",
        "import pathlib\n",
        "from datetime import datetime\n",
        "\n",
        "# -------------------- CONFIGURA√á√ïES INTELIGENTES --------------------\n",
        "if \"__file__\" in globals():\n",
        "    ROOT_DIR = pathlib.Path(__file__).resolve().parent\n",
        "else:\n",
        "    ROOT_DIR = pathlib.Path().resolve().parent\n",
        "\n",
        "DB_PATH = ROOT_DIR / \"data\" / \"ecommerce_realista.db\"\n",
        "EXPORT_PATH = ROOT_DIR / \"data_export\"\n",
        "os.makedirs(EXPORT_PATH, exist_ok=True)\n",
        "\n",
        "logging.basicConfig(\n",
        "    filename=f'{EXPORT_PATH}/log_execucao.txt',\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "\n",
        "# -------------------- FUN√á√ïES --------------------\n",
        "def carregar_dados(db_path: str):\n",
        "    \"\"\"\n",
        "    Conecta ao banco SQLite e carrega as tabelas principais.\n",
        "\n",
        "    Par√¢metros\n",
        "    ----------\n",
        "    db_path : str\n",
        "        Caminho do arquivo .db que cont√©m as tabelas `clientes`,\n",
        "        `produtos` e `vendas`.\n",
        "\n",
        "    Retorna\n",
        "    -------\n",
        "    tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]\n",
        "        Tr√™s DataFrames correspondentes √†s tabelas:\n",
        "        clientes, produtos e vendas.\n",
        "\n",
        "    Exce√ß√µes\n",
        "    --------\n",
        "    FileNotFoundError\n",
        "        Caso o arquivo .db n√£o seja encontrado.\n",
        "    sqlite3.Error\n",
        "        Caso ocorra algum erro de leitura no banco de dados.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with sqlite3.connect(db_path) as conn:\n",
        "            clientes = pd.read_sql(\"SELECT * FROM clientes\", conn)\n",
        "            produtos = pd.read_sql(\"SELECT * FROM produtos\", conn)\n",
        "            vendas = pd.read_sql(\"SELECT * FROM vendas\", conn)\n",
        "        logging.info(\"Tabelas carregadas com sucesso.\")\n",
        "        return clientes, produtos, vendas\n",
        "    except FileNotFoundError:\n",
        "        logging.error(f\"Banco de dados n√£o encontrado em {db_path}\")\n",
        "        raise\n",
        "    except sqlite3.Error as e:\n",
        "        logging.error(f\"Erro ao carregar tabelas: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def consolidar_dados(clientes: pd.DataFrame, produtos: pd.DataFrame, vendas: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Consolida as tabelas `vendas`, `produtos` e `clientes` em um √∫nico DataFrame.\n",
        "\n",
        "    Par√¢metros\n",
        "    ----------\n",
        "    clientes : pd.DataFrame\n",
        "        Tabela contendo informa√ß√µes de clientes.\n",
        "    produtos : pd.DataFrame\n",
        "        Tabela contendo informa√ß√µes de produtos.\n",
        "    vendas : pd.DataFrame\n",
        "        Tabela contendo as vendas realizadas.\n",
        "\n",
        "    Retorna\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        DataFrame unificado com todas as informa√ß√µes e colunas adicionais\n",
        "        de data formatada e per√≠odo (`ano_mes`).\n",
        "\n",
        "    Exce√ß√µes\n",
        "    --------\n",
        "    KeyError\n",
        "        Caso as colunas esperadas ('id_produto', 'id_cliente', 'data_venda')\n",
        "        n√£o existam em alguma tabela.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = (\n",
        "            vendas.merge(produtos, on='id_produto', how='left')\n",
        "                  .merge(clientes, on='id_cliente', how='left')\n",
        "        )\n",
        "        df['data_venda'] = pd.to_datetime(df['data_venda'])\n",
        "        df['ano_mes'] = df['data_venda'].dt.to_period('M')\n",
        "        logging.info(\"Dados consolidados com sucesso.\")\n",
        "        return df\n",
        "    except KeyError as e:\n",
        "        logging.error(f\"Erro de coluna ao consolidar dados: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def gerar_resumos(df: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Gera an√°lises resumidas e o ticket m√©dio do e-commerce.\n",
        "\n",
        "    Par√¢metros\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame consolidado com informa√ß√µes de vendas, clientes e produtos.\n",
        "\n",
        "    Retorna\n",
        "    -------\n",
        "    tuple[pd.DataFrame, pd.DataFrame, float]\n",
        "        - resumo_cat : faturamento total por categoria de produto\n",
        "        - resumo_cli : faturamento total por cliente\n",
        "        - ticket_medio : valor m√©dio das vendas (float)\n",
        "\n",
        "    Notas\n",
        "    -----\n",
        "    Esta fun√ß√£o √© usada para gerar indicadores de neg√≥cio, como:\n",
        "    - categorias que mais faturam\n",
        "    - clientes mais valiosos\n",
        "    - desempenho m√©dio de venda\n",
        "    \"\"\"\n",
        "    resumo_cat = df.groupby('categoria', as_index=False)['valor_total'].sum()\n",
        "    resumo_cat.rename(columns={'valor_total': 'faturamento_total'}, inplace=True)\n",
        "\n",
        "    resumo_cli = df.groupby('nome', as_index=False)['valor_total'].sum()\n",
        "    resumo_cli.rename(columns={'valor_total': 'faturamento_cliente'}, inplace=True)\n",
        "\n",
        "    ticket_medio = df['valor_total'].mean()\n",
        "    logging.info(f\"Ticket m√©dio calculado: R$ {ticket_medio:.2f}\")\n",
        "    return resumo_cat, resumo_cli, ticket_medio\n",
        "\n",
        "\n",
        "def exportar_arquivos(df: pd.DataFrame, resumo_cat: pd.DataFrame, resumo_cli: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Exporta os DataFrames gerados para arquivos .csv e registra a execu√ß√£o.\n",
        "\n",
        "    Par√¢metros\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame consolidado com todas as vendas.\n",
        "    resumo_cat : pd.DataFrame\n",
        "        Resumo de faturamento por categoria.\n",
        "    resumo_cli : pd.DataFrame\n",
        "        Resumo de faturamento por cliente.\n",
        "\n",
        "    Retorna\n",
        "    -------\n",
        "    None\n",
        "        Exporta os arquivos para a pasta `data_export`.\n",
        "\n",
        "    Exce√ß√µes\n",
        "    --------\n",
        "    PermissionError\n",
        "        Caso algum arquivo CSV esteja aberto no momento da exporta√ß√£o.\n",
        "    \"\"\"\n",
        "    data_exec = datetime.now().strftime('%Y-%m-%d')\n",
        "    try:\n",
        "        df.to_csv(f'{EXPORT_PATH}/vendas_detalhadas_{data_exec}.csv', index=False)\n",
        "        resumo_cat.to_csv(f'{EXPORT_PATH}/resumo_categorias_{data_exec}.csv', index=False)\n",
        "        resumo_cli.to_csv(f'{EXPORT_PATH}/resumo_clientes_{data_exec}.csv', index=False)\n",
        "        logging.info(\"Arquivos CSV exportados com sucesso.\")\n",
        "    except PermissionError:\n",
        "        logging.error(\"Erro: Feche os arquivos CSV antes de exportar novamente.\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Erro ao exportar arquivos: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal que coordena a execu√ß√£o do pipeline de automa√ß√£o.\n",
        "\n",
        "    Etapas\n",
        "    ------\n",
        "    1. Verifica a exist√™ncia do banco de dados.\n",
        "    2. Carrega as tabelas principais.\n",
        "    3. Consolida os dados em um √∫nico DataFrame.\n",
        "    4. Gera an√°lises resumidas e calcula o ticket m√©dio.\n",
        "    5. Exporta os resultados e atualiza o log de execu√ß√£o.\n",
        "\n",
        "    Retorna\n",
        "    -------\n",
        "    None\n",
        "        Exibe no terminal mensagens de progresso e sucesso.\n",
        "    \"\"\"\n",
        "    print(\"üöÄ Iniciando automa√ß√£o de dados...\\n\")\n",
        "    if not os.path.exists(DB_PATH):\n",
        "        raise FileNotFoundError(\"Banco de dados n√£o encontrado.\")\n",
        "    clientes, produtos, vendas = carregar_dados(DB_PATH)\n",
        "    df = consolidar_dados(clientes, produtos, vendas)\n",
        "    resumo_cat, resumo_cli, ticket_medio = gerar_resumos(df)\n",
        "    exportar_arquivos(df, resumo_cat, resumo_cli)\n",
        "    print(f\"‚úÖ Processo conclu√≠do com sucesso! Ticket m√©dio: R$ {ticket_medio:.2f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resultados Esperados\n",
        "\n",
        "- Conex√£o bem-sucedida ao banco `ecommerce_realista.db`\n",
        "- Gera√ß√£o dos arquivos:\n",
        "  - `vendas_detalhadas_<data>.csv`\n",
        "  - `resumo_categorias_<data>.csv`\n",
        "  - `resumo_clientes_<data>.csv`\n",
        "- Atualiza√ß√£o autom√°tica do arquivo `log_execucao.txt` com data e hora.\n",
        "- Exibi√ß√£o do ticket m√©dio e confirma√ß√£o de sucesso da automa√ß√£o."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
